{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Word2Vec es una técnica que se utiliza para obtener representaciones vectoriales de palabras. Estas representaciones son útiles para realizar tareas de procesamiento de lenguaje natural, como la clasificación de texto, la traducción automática, la generación de texto, etc. \n",
    "\n",
    "Esta técnica se basa en la hipótesis distribucional, que establece que las palabras que aparecen en contextos similares tienen significados similares. Por lo tanto, Word2Vec se entrena para predecir las palabras vecinas de una palabra dada, utilizando un corpus de texto como datos de entrenamiento.\n",
    "\n",
    "Tiene dos variantes principales: Skip-gram y Continuous Bag of Words (CBOW). La diferencia entre ambas radica en la forma en que se plantea el problema de predicción. En el caso de Skip-gram, se predice el contexto a partir de una palabra dada, mientras que en CBOW se predice la palabra a partir de su contexto.\n",
    "\n",
    "Por ejemplo en el texto \"El gato come pescado\", si utilizamos una ventana de tamaño 2, el contexto de la palabra \"come\" sería \"El gato pescado\". En el caso de Skip-gram, se trataría de predecir \"El\", \"gato\", \"pescado\" a partir de \"come\":\n",
    "\n",
    "| Entrada | Salida |\n",
    "|---------|--------|\n",
    "| come    | El     |\n",
    "| come    | gato   |\n",
    "| come    | pescado|\n",
    "\n",
    "Mientras que en el caso de CBOW, se trataría de predecir \"come\" a partir de \"El\", \"gato\", \"pescado\":\n",
    "\n",
    "| Entrada | Salida |\n",
    "|---------|--------|\n",
    "| El      | come   |\n",
    "| gato    | come   |\n",
    "| pescado | come   |\n",
    "\n",
    "En este notebook, vamos a utilizar la implementación de Word2Vec de la librería Gensim para entrenar un modelo de Skip-gram y explorar las representaciones vectoriales de palabras obtenidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Librerias necesarias Word2Vec\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar el texto\n",
    "\n",
    "Para este ejercicio inicial usaremos un texto sencillo, el cual se cargará en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_1 = \"\"\"Hace varios años, en el pelotón de fusilamiento, el coronel Aureliano Buendía había de recordar aquella tarde remota en que su padre lo llevó a conocer el hielo. \"\"\"\n",
    "texto_2 = \"\"\"Hace tanto tiempo que no me acuerdo de nada, pero recuerdo que mi padre me llevó a conocer el hielo. \"\"\"\n",
    "texto_3 = \"\"\"Hace tiempo que ocurrió la era de hielo, ahorita que solo soy un  perezoso recuerdo aquellos días tan bellos con mis amigos, un mamut y un dientes de sable. \"\"\"\n",
    "\n",
    "corpus = [texto_1, texto_2, texto_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento\n",
    "\n",
    "El preprocesamiento es una etapa importante en el procesamiento de lenguaje natural. En esta etapa se eliminan las palabras que no aportan información, como los signos de puntuación, las palabras vacías, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Preprocesamiento de texto ####################\n",
    "def preprocesamiento(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"[\\W\\d_]+\", \" \", texto)\n",
    "    texto = texto.split()\n",
    "\n",
    "    return texto\n",
    "\n",
    "corpus_procesado = [preprocesamiento(texto) for texto in corpus]\n",
    "\n",
    "print(corpus_procesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del modelo\n",
    "\n",
    "Una vez que se ha preprocesado el texto, se puede entrenar el modelo Word2Vec. Para ello, se utiliza la clase `Word2Vec` de la librería Gensim. Se pueden configurar varios parámetros, como el tamaño del vector, la ventana de contexto, el número de iteraciones, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Entrenamiento de modelo Word2Vec ####################\n",
    "\n",
    "modelo = Word2Vec(corpus_procesado, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "### Aqui cada parametro significa lo siguiente:\n",
    "# vector_size: Dimension de los vectores de palabras\n",
    "# window: Numero de palabras que se toman en cuenta para predecir la siguiente palabra\n",
    "# min_count: Frecuencia minima de palabras para ser considerada\n",
    "# sg: 0 para CBOW y 1 para Skip-gram\n",
    "\n",
    "\n",
    "\n",
    "print(modelo.wv.key_to_index)\n",
    "print(modelo.wv[\"hielo\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploración de las representaciones vectoriales\n",
    "\n",
    "Una vez entrenado el modelo, se pueden explorar las representaciones vectoriales de las palabras. Por ejemplo, se pueden obtener las palabras más similares a una palabra dada, o realizar operaciones de álgebra de vectores para encontrar relaciones entre palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Explorar representaciones vectoriales de palabras ####\n",
    "\n",
    "print(modelo.wv.most_similar(\"hielo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.wv.most_similar(\"padre\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALgebra de palabras ###\n",
    "\n",
    "print(modelo.wv.most_similar(positive=[\"hielo\", \"padre\"], negative=[\"perezoso\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusiones\n",
    "\n",
    "En este notebook, hemos visto cómo entrenar un modelo Word2Vec utilizando la librería Gensim y explorar las representaciones vectoriales de palabras obtenidas. Estas representaciones son útiles para realizar tareas de procesamiento de lenguaje natural, como la clasificación de texto, la traducción automática, la generación de texto, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_ean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
