{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Generaci\u00f3n de Texto con LSTM usando 'Cien A\u00f1os de Soledad'\n\n", "En este cuaderno, vamos a implementar un modelo LSTM que ser\u00e1 entrenado usando el texto del libro 'Cien A\u00f1os de Soledad' de Gabriel Garc\u00eda M\u00e1rquez.\n", "El objetivo es que el modelo aprenda el estilo literario y sea capaz de generar texto similar al del autor.\n\n", "## Requisitos previos\n", "- Python 3.7+\n", "- TensorFlow\n", "- Numpy\n", "- Matplotlib\n\n", "## Objetivo\n", "1. Preprocesar el texto de 'Cien A\u00f1os de Soledad'.\n", "2. Implementar un modelo LSTM para la generaci\u00f3n de texto.\n", "3. Entrenar el modelo y generar texto nuevo."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Cargando y Preprocesando el Texto\n", "Cargaremos el texto de 'Cien A\u00f1os de Soledad' y lo preprocesaremos para convertirlo en secuencias de texto adecuadas para el entrenamiento del modelo LSTM."]}, {"cell_type": "code", "metadata": {}, "source": ["import tensorflow as tf\n", "from tensorflow.keras.preprocessing.text import Tokenizer\n", "from tensorflow.keras.preprocessing.sequence import pad_sequences\n", "import numpy as np\n\n", "# Cargar el texto de 'Cien A\u00f1os de Soledad'\n", "with open('/mnt/data/CAS.txt', 'r', encoding='utf-8') as file:\n", "    text = file.read()\n\n", "# Preprocesamiento del texto\n", "corpus = text.lower().split(\"\\n\")\n\n", "# Tokenizaci\u00f3n\n", "tokenizer = Tokenizer()\n", "tokenizer.fit_on_texts(corpus)\n", "total_words = len(tokenizer.word_index) + 1\n\n", "# Convertir texto en secuencias de palabras\n", "input_sequences = []\n", "for line in corpus:\n", "    token_list = tokenizer.texts_to_sequences([line])[0]\n", "    for i in range(1, len(token_list)):\n", "        n_gram_sequence = token_list[:i+1]\n", "        input_sequences.append(n_gram_sequence)\n\n", "# Padding para igualar las secuencias\n", "max_sequence_len = max([len(x) for x in input_sequences])\n", "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n\n", "# Dividir en caracter\u00edsticas y etiquetas\n", "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n", "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n\n", "X.shape, y.shape"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Creando el Modelo LSTM\n", "Ahora crearemos el modelo LSTM que ser\u00e1 entrenado para predecir la siguiente palabra en una secuencia, basado en el estilo literario del libro."]}, {"cell_type": "code", "metadata": {}, "source": ["from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Embedding, LSTM, Dense\n\n", "# Crear el modelo LSTM\n", "model = Sequential()\n", "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n", "model.add(LSTM(100))\n", "model.add(Dense(total_words, activation='softmax'))\n\n", "# Compilar el modelo\n", "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n", "# Resumen del modelo\n", "model.summary()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Entrenando el Modelo\n", "Entrenaremos el modelo durante 100 \u00e9pocas para que aprenda las secuencias de texto y las relaciones entre palabras."]}, {"cell_type": "code", "metadata": {}, "source": ["# Entrenar el modelo\n", "history = model.fit(X, y, epochs=100, verbose=1)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Generaci\u00f3n de Texto\n", "Una vez que el modelo est\u00e9 entrenado, podemos usarlo para generar texto nuevo en el estilo de 'Cien A\u00f1os de Soledad'."]}, {"cell_type": "code", "metadata": {}, "source": ["def generar_texto(model, tokenizer, seed_text, max_sequence_len, n_words):\n", "    for _ in range(n_words):\n", "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n", "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n", "        predicted = np.argmax(model.predict(token_list), axis=-1)\n", "        output_word = \"\"\n", "        for word, index in tokenizer.word_index.items():\n", "            if index == predicted:\n", "                output_word = word\n", "                break\n", "        seed_text += \" \" + output_word\n", "    return seed_text\n\n", "# Generar texto\n", "print(generar_texto(model, tokenizer, 'muchos a\u00f1os despu\u00e9s', max_sequence_len, 50))"], "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 5}