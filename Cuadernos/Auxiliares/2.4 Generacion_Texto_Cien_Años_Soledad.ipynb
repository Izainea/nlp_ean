{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Generación de Texto con LSTM usando 'Cien Años de Soledad'\n","\n","En este cuaderno, vamos a implementar un modelo LSTM que será entrenado usando el texto del libro 'Cien Años de Soledad' de Gabriel García Márquez.\n","El objetivo es que el modelo aprenda el estilo literario y sea capaz de generar texto similar al del autor.\n","\n","## Requisitos previos\n","- Python 3.7+\n","- TensorFlow\n","- Numpy\n","- Matplotlib\n","\n","## Objetivo\n","1. Preprocesar el texto de 'Cien Años de Soledad'.\n","2. Implementar un modelo LSTM para la generación de texto.\n","3. Entrenar el modelo y generar texto nuevo."]},{"cell_type":"markdown","metadata":{},"source":["## 1. Cargando y Preprocesando el Texto\n","Cargaremos el texto de 'Cien Años de Soledad' y lo preprocesaremos para convertirlo en secuencias de texto adecuadas para el entrenamiento del modelo LSTM."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","# Cargar el texto de 'Cien Años de Soledad'\n","with open('https://raw.githubusercontent.com/Izainea/nlp_ean/main/Datos/Datos%20Crudos/CAS.txt', 'r', encoding='utf-8') as file:\n","    text = file.read()\n","\n","# Preprocesamiento del texto\n","corpus = text.lower().split(\"\\n\")\n","\n","# Tokenización\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(corpus)\n","total_words = len(tokenizer.word_index) + 1\n","\n","# Convertir texto en secuencias de palabras\n","input_sequences = []\n","for line in corpus:\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)\n","\n","# Padding para igualar las secuencias\n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n","\n","# Dividir en características y etiquetas\n","X, y = input_sequences[:,:-1], input_sequences[:,-1]\n","y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n","\n","X.shape, y.shape"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Creando el Modelo LSTM\n","Ahora crearemos el modelo LSTM que será entrenado para predecir la siguiente palabra en una secuencia, basado en el estilo literario del libro."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","# Crear el modelo LSTM\n","model = Sequential()\n","model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n","model.add(LSTM(100))\n","model.add(Dense(total_words, activation='softmax'))\n","\n","# Compilar el modelo\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Resumen del modelo\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Entrenando el Modelo\n","Entrenaremos el modelo durante 100 épocas para que aprenda las secuencias de texto y las relaciones entre palabras."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Entrenar el modelo\n","history = model.fit(X, y, epochs=100, verbose=1)"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Generación de Texto\n","Una vez que el modelo esté entrenado, podemos usarlo para generar texto nuevo en el estilo de 'Cien Años de Soledad'."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generar_texto(model, tokenizer, seed_text, max_sequence_len, n_words):\n","    for _ in range(n_words):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        predicted = np.argmax(model.predict(token_list), axis=-1)\n","        output_word = \"\"\n","        for word, index in tokenizer.word_index.items():\n","            if index == predicted:\n","                output_word = word\n","                break\n","        seed_text += \" \" + output_word\n","    return seed_text\n","\n","# Generar texto\n","print(generar_texto(model, tokenizer, 'muchos años después', max_sequence_len, 50))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","version":"3.8.5"}},"nbformat":4,"nbformat_minor":5}
