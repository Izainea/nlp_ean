{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2: Clasificación de Noticias Usando RNNs y LSTMs\n",
    "\n",
    "### Propósito de Aprendizaje\n",
    "Adquirir habilidades prácticas en el preprocesamiento de datos textuales y en la implementación de modelos avanzados de RNN y LSTM para la clasificación de noticias en categorías especializadas como deportes, cultura, economía y justicia. Al finalizar, los estudiantes habrán desarrollado la capacidad de construir, entrenar y evaluar estos modelos, así como de comparar su rendimiento de manera crítica.\n",
    "\n",
    "### Producto(s)\n",
    "- **Cuaderno Jupyter (Jupyter Notebook):** Documentar el proceso completo de preprocesamiento, construcción, entrenamiento, evaluación y comparación de modelos RNN y LSTM.\n",
    "- **Informe (PDF/Markdown):** Un documento que resuma los hallazgos, compare los modelos RNN y LSTM, y discuta las implicaciones prácticas de los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Carga y Exploración de Datos\n",
    "**Objetivo:** Familiarizarse con el conjunto de datos y comprender la distribución de las categorías.\n",
    "\n",
    "**Acciones:**\n",
    "- Cargar el archivo `Noticias.xlsx` que contiene las noticias.\n",
    "- Explorar la distribución de la columna `Etiqueta` para ver cuántas noticias pertenecen a cada categoría.\n",
    "- Visualizar esta distribución mediante gráficos para identificar las categorías más frecuentes.\n",
    "\n",
    "**Contexto:** La columna `Etiqueta` en el conjunto de datos contiene varias categorías, algunas de las cuales no son especializadas o no contienen un enfoque específico (por ejemplo, \"archivo\"). Para esta actividad, nos centraremos en noticias de las categorías especializadas: deportes, cultura, economía y justicia. Estas categorías son relevantes porque representan temas con un enfoque claro y específico, lo que hace que la clasificación sea más útil y aplicable en el análisis de noticias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "file_path = '../../Datos/Datos Crudos/Noticias.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "## Quitamos los nulos\n",
    "data = data.dropna()\n",
    "\n",
    "# Mostrar las primeras filas del conjunto de datos\n",
    "data.head()\n",
    "\n",
    "# Visualizar la distribución de las etiquetas\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data['Etiqueta'])\n",
    "plt.title('Distribución de las Etiquetas')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Filtrado de Datos\n",
    "**Objetivo:** Limitar el conjunto de datos a las categorías relevantes para garantizar que el modelo se entrene y evalúe en temas especializados.\n",
    "\n",
    "**Acciones:**\n",
    "- Excluir las noticias que pertenecen a la categoría \"archivo\" y cualquier otra que no esté en las categorías de deportes, cultura, economía y justicia.\n",
    "- Asegurarse de que el conjunto de datos resultante tenga una distribución equilibrada para estas categorías, en la medida de lo posible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las categorías relevantes y excluir \"archivo\"\n",
    "categorias_relevantes = ['deportes', 'cultura', 'economia', 'justicia']\n",
    "data_filtrada = data[data['Etiqueta'].isin(categorias_relevantes)]\n",
    "\n",
    "# Visualizar la distribución de las etiquetas después del filtrado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data_filtrada['Etiqueta'])\n",
    "plt.title('Distribución de las Etiquetas (Filtradas)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Preprocesamiento de Texto\n",
    "**Objetivo:** Preparar los datos textuales para el entrenamiento del modelo.\n",
    "\n",
    "**Acciones:**\n",
    "- Convertir todo el texto a minúsculas para uniformidad.\n",
    "- Eliminar puntuación y números para reducir el ruido en los datos.\n",
    "- Eliminar palabras comunes (stop words) que no aportan significado específico al análisis.\n",
    "- Tokenizar el texto, es decir, dividir el texto en palabras individuales.\n",
    "\n",
    "\n",
    "Para este ejercicio debe instalarse la libreria keras y tensorflow, para ello se debe ejecutar el siguiente comando en la consola de anaconda:\n",
    "```python\n",
    "pip install keras tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import keras_nlp\n",
    "import tensorflow as tf\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Función de preprocesamiento\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if c not in string.punctuation and not c.isdigit()])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('spanish')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "data_filtrada['contenido_preprocesado'] = data_filtrada['contenido'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar el texto\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenización y padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_filtrada['contenido_preprocesado'])\n",
    "sequences = tokenizer.texts_to_sequences(data_filtrada['contenido_preprocesado'])\n",
    "word_index = tokenizer.word_index\n",
    "max_len = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Mostrar algunas secuencias preprocesadas\n",
    "padded_sequences[:5]\n",
    "\n",
    "## También puede usar las técnicas de preprocesamiento de texto y de embedding que hicimos anteriormente\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4: División del Conjunto de Datos\n",
    "**Objetivo:** Crear conjuntos de datos de entrenamiento y validación para evaluar el modelo.\n",
    "\n",
    "**Acciones:**\n",
    "- Dividir el conjunto de datos preprocesado en dos partes: uno para entrenar el modelo y otro para validarlo.\n",
    "- Asegurarse de que la división sea aleatoria pero mantenga una proporción similar de las categorías en ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificación de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "data_filtrada['Etiqueta_codificada'] = label_encoder.fit_transform(data_filtrada['Etiqueta'])\n",
    "\n",
    "# División del conjunto de datos\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, data_filtrada['Etiqueta_codificada'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Mostrar tamaño de los conjuntos de datos\n",
    "len(X_train), len(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Construcción y Entrenamiento de Modelos RNN\n",
    "\n",
    "**Objetivo:** Implementar un modelo de Red Neuronal Recurrente (RNN) para clasificar noticias en las categorías especializadas.\n",
    "\n",
    "**Acciones:**\n",
    "- Construir un modelo RNN utilizando capas de Embedding, SimpleRNN y Dense.\n",
    "- Compilar el modelo con una función de pérdida adecuada y un optimizador.\n",
    "- Entrenar el modelo con el conjunto de datos de entrenamiento y validar su rendimiento con el conjunto de datos de validación.\n",
    "- Evaluar el rendimiento del modelo en términos de precisión y pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# Construcción del modelo RNN\n",
    "# Haga cambios en la arquitectura del modelo para mejorar su rendimiento\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(input_dim=len(word_index) + 1, output_dim=128, input_length=max_len))\n",
    "model_rnn.add(SimpleRNN(units=64, return_sequences=False))\n",
    "model_rnn.add(Dense(units=len(categorias_relevantes), activation='softmax'))\n",
    "\n",
    "# Compilación del modelo\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history_rnn = model_rnn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Visualización de resultados del modelo RNN\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_rnn.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history_rnn.history['val_accuracy'], label='Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.title('Curvas de Aprendizaje - RNN')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Construcción y Entrenamiento de Modelos LSTM\n",
    "\n",
    "**Objetivo:** Implementar un modelo de Red Neuronal LSTM (Long Short-Term Memory) para clasificar noticias en las categorías especializadas.\n",
    "\n",
    "**Acciones:**\n",
    "\n",
    "- Construir un modelo LSTM utilizando capas de Embedding, LSTM y Dense.\n",
    "- Compilar el modelo con una función de pérdida adecuada y un optimizador.\n",
    "- Entrenar el modelo con el conjunto de datos de entrenamiento y validar su rendimiento con el conjunto de datos de validación.\n",
    "- Evaluar el rendimiento del modelo en términos de precisión y pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "# Construcción del modelo LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=len(word_index) + 1, output_dim=128, input_length=max_len))\n",
    "model_lstm.add(LSTM(units=64, return_sequences=False))\n",
    "model_lstm.add(Dense(units=len(categorias_relevantes), activation='softmax'))\n",
    "\n",
    "# Compilación del modelo\n",
    "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history_lstm = model_lstm.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Visualización de resultados del modelo LSTM\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_lstm.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history_lstm.history['val_accuracy'], label='Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.title('Curvas de Aprendizaje - LSTM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Comparación de Modelos y Análisis de Resultados\n",
    "\n",
    "**Objetivo:** Comparar los modelos RNN y LSTM en términos de rendimiento y analizar los resultados obtenidos.\n",
    "\n",
    "**Acciones:**\n",
    "- Comparar la precisión y la pérdida de los modelos RNN y LSTM en el conjunto de datos de validación.\n",
    "- Calcula otras métricas de evaluación como la sensibilidad, la especificidad y el puntaje F1.\n",
    "- Discutir las fortalezas y debilidades de cada modelo en función de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluar modelos en el conjunto de validación\n",
    "y_pred_rnn = model_rnn.predict(X_val).argmax(axis=1)\n",
    "y_pred_lstm = model_lstm.predict(X_val).argmax(axis=1)\n",
    "\n",
    "# Calcular métricas de rendimiento\n",
    "report_rnn = classification_report(y_val, y_pred_rnn, target_names=categorias_relevantes)\n",
    "report_lstm = classification_report(y_val, y_pred_lstm, target_names=categorias_relevantes)\n",
    "\n",
    "print(\"RNN Classification Report:\")\n",
    "print(report_rnn)\n",
    "\n",
    "print(\"LSTM Classification Report:\")\n",
    "print(report_lstm)\n",
    "\n",
    "# Visualización de resultados\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_rnn.history['accuracy'], label='RNN Entrenamiento')\n",
    "plt.plot(history_rnn.history['val_accuracy'], label='RNN Validación')\n",
    "plt.plot(history_lstm.history['accuracy'], label='LSTM Entrenamiento')\n",
    "plt.plot(history_lstm.history['val_accuracy'], label='LSTM Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.title('Curvas de Aprendizaje - RNN vs LSTM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8: Conclusiones y Recomendaciones\n",
    "\n",
    "**Objetivo:** Resumir los hallazgos y proporcionar recomendaciones basadas en los resultados obtenidos.\n",
    "\n",
    "**Acciones:**\n",
    "- Resumir las principales conclusiones de la comparación entre los modelos RNN y LSTM.\n",
    "- Proporcionar recomendaciones para mejorar el rendimiento de los modelos o explorar enfoques alternativos.\n",
    "- Discutir las implicaciones prácticas de los resultados y cómo podrían aplicarse en un contexto real.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_ean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
